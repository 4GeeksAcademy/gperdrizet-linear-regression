{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression: health insurance cost\n",
    "\n",
    "## Notebook setup\n",
    "\n",
    "Handle imports of necessary modules up-front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Custom functions for this notebook\n",
    "import helper_functions as funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Data loading\n",
    "\n",
    "### 1.1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/4GeeksAcademy/linear-regression-project-tutorial/main/medical_insurance_cost.csv'\n",
    "data_df = pd.read_csv(data_url, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Save local copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for raw data\n",
    "Path('../data/raw').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save a local copy of the raw data\n",
    "data_df.to_parquet('../data/raw/medical-insurance-cost.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains information about 1,338 insurance policyholders with 7 features:\n",
    "- **age**: Age of the policyholder (numerical)\n",
    "- **sex**: Gender (categorical: male/female) \n",
    "- **bmi**: Body Mass Index (numerical)\n",
    "- **children**: Number of children covered (numerical)\n",
    "- **smoker**: Smoking status (categorical: yes/no)\n",
    "- **region**: Geographic region (categorical: southeast, southwest, northeast, northwest)\n",
    "- **charges**: Insurance charges - our target variable (numerical)\n",
    "\n",
    "This is our target variable that we want to predict using the other features.\n",
    "\n",
    "## 2. EDA\n",
    "\n",
    "### 2.1. Data composition\n",
    "\n",
    "#### 2.1.1. Interval features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at some descriptive statistics for the numerical features - what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distributions of the numerical features - what do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the level counts of the categorical features - what do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature interactions\n",
    "\n",
    "#### 2.2.1. Interval features vs label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between the numerical features and the target variable - what do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Nominal features vs label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationships between the categorical features and the target variable - what do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation\n",
    "\n",
    "### 3.1. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% train and 20% test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into 80% training (1,070 samples) and 20% testing (268 samples) to evaluate model performance on unseen data. This helps prevent overfitting and gives us a realistic estimate of how the model will perform in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical features using OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use one-hot encoding for categorical variables, which creates binary columns for each category. The `drop='first'` parameter prevents multicollinearity by dropping one category as a reference. \n",
    "\n",
    "Our dataset now has the following encoded features:\n",
    "- Original: sex, smoker, region (3 categorical columns)  \n",
    "- Encoded: sex_male, smoker_yes, region_northwest, region_southeast, region_southwest (5 binary columns)\n",
    "\n",
    "This allows our linear model to properly handle categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the results\n",
    "results = {\n",
    "    'RMSE': {},\n",
    "    'R2': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a model baseline using a strategy that you devise - what is the 'easiest' 'prediction' you can make?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any useful model should significantly outperform this baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a default linear regression model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the RMSE and R² for the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Predicted vs Actual plot\n",
    "axs[0].scatter(labels, predictions, color='black', alpha=0.6, s=30)\n",
    "axs[0].plot([min(labels), max(labels)], [min(labels), max(labels)], \n",
    "            'r--', linewidth=2, label='Perfect prediction')\n",
    "axs[0].set_xlabel('Actual charges ($)')\n",
    "axs[0].set_ylabel('Predicted charges ($)')\n",
    "axs[0].set_title(f'Predicted vs Actual Charges')\n",
    "axs[0].legend()\n",
    "axs[0].grid(alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "residuals = predictions - labels\n",
    "axs[1].scatter(predictions, residuals, color='black', alpha=0.6, s=30)\n",
    "axs[1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "axs[1].set_xlabel('Predicted charges ($)')\n",
    "axs[1].set_ylabel('Residuals ($)')\n",
    "axs[1].set_title(f'Residuals vs Predicted')\n",
    "axs[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted vs Actual Plot:**\n",
    "- Points should lie on the red diagonal line for perfect predictions\n",
    "\n",
    "**Residuals Plot:**\n",
    "- Residuals should be randomly scattered around zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimization\n",
    "\n",
    "### 5.1. Feature transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to improve model performane by scaling the data with StandardScaler or MinMaxScaler, then re-training the model\n",
    "# is there any improvement in the RMSE and R²? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devise a additional strategy to improve the model performance - what features can you engineer or transform?\n",
    "# Try it out and see if it improves the RMSE and R². Did it work? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results\n",
    "\n",
    "### 6.1. Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the RMSE and R² results for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Winning model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model based on RMSE and R² Evaluate it on the test data. Include plots of the predicted vs actual and residuals vs predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
